################# Overview ################
OpenStack software controls large pools of compute, storage, and networking resources throughout a datacenter, 
managed through a dashboard or via the OpenStack API. 
OpenStack works with popular enterprise and open source technologies making it ideal for heterogeneous infrastructure.
The software platform consists of six core services as well as 13 optional serices
Each service offers an API which can be access via coresponding CLI as well


#####Core Services Overview

Keystone - identity service
Provides an authentication and authorization service for other openstack components, provides a catalog of endpoints for all openstack services
keystone terminology:
  service - refers to service running in openstack (nova, swift, glance...)
  endpoint - address where you can access a given service, can be configured on three URLs: public facing url(end users), administration url(administrators), internal url(presenting the services to the public url)
  catalog - listing of different endpoints
  project - set of any resource assigned to an isolated group of users
  user - used by services and administrators to manage openstack cloud (it must be assigned to project and be assigned a role)
  role - permissions given to users within a project (assigned directly to users and groups or inherited from domains)
  token - identifying credential associated with user
  group - collection of users 
  credential - username and password, username and API key etc..
  domain - collection of projects, groups and users that define the administrative boundaries for managing openstack
  region - separates openstack environments that have dedicated API endpoints but utilize a common keystone service


Glance - image service
Stores and retrives  virtaul machine disk images , openstack compute makes use of glance during instance provisioning

Nova - compute service 
Manages the lifecycle of compute instances, responsibilities include spawning, scheduling and decommissioning of virtual machines on demand
Components:
  nova api - receives and responds to user requests, whether they are direct api calls or via the cli tools or dashboard
  nova database - stores the current state of all objects usually mysql but sqllite and postgresql can be used too(Nova conductor service is the only service that writes to the database)
  nova scheduler - it is used to determine how to dispatch compute requests
  nova's message queue - unified way for collaboration between sub-components , usually rabbitmq
  nova conductor - enables openstack to function without compute nodes accessing the database
  
 
Neturon - networking service
enables network connectivity as a service for other openstack services, such as Nova
Has a pluggable architecture that supports many popular networking vendors and technologies

Horizon - web based dashboard
provides portal to interact with underlying openstack services such as:
launching an intance , assigning IP addresses, configuring access controls and more.

Cinder - block storage service
Provides persistent block storage for instances, it has pluggable driver architecture

Swift - object storage
Stores and retrives arbitrary unstructed data objects via REST api
it is highly fault tolerant with its data replication and scale-out architecture
components:
  ring - represents a mapping between the names of entities stored on a disk and their physical locations
  zones - a zone can be a single drive or a grouping of a few drives
  accounts, containers, objects - each account and container is an individual sqllite database distributed across the cluster
  account database contains the list of containers in that account , container db contains the list of objects stored in the container
  partitions - collection of stored data, including account dbs and objects  


Heat - orchestration service 
it orchestrates multiple composite cloud applications by using either the native HOT template or the AWS CloudFormation template format
through both an openstack native REST API and a CloudFormation compatible query api


########### Intallation of basic openstack cloud ##############

#Add repository - ubuntu 16
add-apt-repository cloud-archive:pike
add-apt-repository cloud-archive:pike-updates

#ubuntu 18
add-apt-repository cloud-archive:rocky
add-apt-repository cloud-archive:rocky-updates

apt-get update; apt-get dist-upgrade -y; apt-get install python-openstackclient -y


### Controller setup

apt-get install mariadb-server python-pymysql

[mysqld]
bind-address = control-IP
default-storage-engine = innodb
innodb_file_per_table = on
max_connections = 4096
collation-server = utf8_general_ci
character-set-server = utf8

apt-get install rabbitmq-server
rabbitmqctl add_user openstack RABBIT_PASS
rabbitmqctl set_permissions openstack ".*" ".*" ".*"

apt-get install memcached python-memcache

#change memcached listen interface and start service


##### Services installation #####

## Keystone install
#On the controll node

apt-get install python-pyasn1 -y

#Create keystone database
create database keystone;
grant all privileges on keystone.* to 'keystone'@'localhost' identified by 'PASSWORD';
grant all privileges on keystone.* to 'keystone'@'%' identified by 'PASSWORD';

apt-get install keystone apache2 libapache2-mod-wsgi -y

vim /etc/keystone/keystone.conf
[database]
connection = mysql+pymysql://keystone:PASSWORD@CONTROL_IP/keystone

[token]
provider = fernet

#Populate database
su -s /bin/sh -c "keystone-manage db_sync" keystone

#Initialize fernet key repositories
keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone
keystone-manage credential_setup --keystone-user keystone --keystone-group keystone

#bootstrap identity service
keystone-manage bootstrap --bootstrap-password PASSWORD --bootstrap-admin-url http://CONTROLER_IP:5000/v3/ --bootstrap-internal-url http://CONTROLER_IP:5000/v3/ --bootstrap-public-url http://CONTROLER_IP:5000/v3/ --bootstrap-region-id RegionOne

#configure apache
vi /etc/apache2/apache2.conf
ServerName CONTROLER_HOSTNAME


#Creating projects, users and roles
export OS_USERNAME=admin
export OS_PASSWORD=viktor123
export OS_PROJECT_NAME=admin
export OS_USER_DOMAIN_NAME=Default
export OS_AUTH_URL=http://10.0.11.160:35357/v3
export OS_IDENTITY_API_VERSION=3

#Service project
openstack project create --domain default --description "Service project" service
openstack project create --domain default --description "Demo project" demo

#Users
openstack user create --domain default --password-prompt demo
openstack role create user
openstack role add --project demo --user demo user

##Verify keystone
vi /etc/keystone/keystone-paste.ini

Remove admin_token_auth from:
[pipeline:public_api]
[pipeline:admin_api]
[pipeline:api_v3]

#unset
unset OS_AUTH_URL OS_PASSWORD

openstack --os-auth-url http://CONTROLLER:5000/v3 --os-project-domain-name Default --os-user-domain-name Default --os-project-name admin --os-username admin token issue
openstack --os-auth-url http://CONTROLLER:5000/v3 --os-project-domain-name Default --os-user-domain-name Default --os-project-name demo --os-username demo token issue

##Credentials file can be created
vi admin-openrc
export OS_USERNAME=admin
export OS_PASSWORD=password
export OS_PROJECT_NAME=admin
export OS_USER_DOMAIN_NAME=Default
export OS_PROJECT_DOMAIN_NAME=Default
export OS_AUTH_URL=http://Controller:5000/v3
export OS_IDENTITY_API_VERSION=3
export OS_IMAGE_API_VERSION=2



##Glance install
#on the control node

#Create glance database
create database glance;
grant all privileges on glance.* to 'glance'@'localhost' identified by 'viktor123';
grant all privileges on glance.* to 'glance'@'%' identified by 'viktor123';

#Create glance user in openstack
. admin-openrc
openstack user create --domain default --password-prompt glance
openstack role add --project service --user glance admin

#Create the service
openstack service create --name glance --description "Openstack Image" image
#endpoints
openstack endpoint create --region RegionOne image public http://10.0.11.160:9292
openstack endpoint create --region RegionOne image internal http://10.0.11.160:9292
openstack endpoint create --region RegionOne image admin http://10.0.11.160:9292

#Install
apt-get install glance -y

vi /etc/glance/glance-api.conf

bind_host = 0.0.0.0

[database]
connection = mysql+pymysql://glance:DB_PASS@10.0.11.160/glance

[keystone_authtoken]
auth_url = http://10.0.11.160:5000
memcached_servers = 10.0.11.160:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = glance
password = PASSWORD
 
[paste_deploy]
flavor = keystone

[glance_store]
stores = file,http
default_store = file
filesystem_store_directory = /var/lib/glance/images


vi /etc/glance/glance-registry.conf
#same config


#Seed DB
su -s /bin/sh -c "glance-manage db_sync" glance

chown -R glance: /etc/glance/
chown -R glance: /var/lib/glance/
systemctl restart glance-registry
systemctl restart glance-api

#Upload test image
wget http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img
openstack image create --file cirros-0.3.5-x86_64-disk.img --disk-format qcow2 --container-format bare --public cirros

openstack image list


##Nova install

#Create database
create database nova_api;
create database nova;
create database nova_cell0;

grant all privileges on nova_api.* to 'nova'@'localhost' identified by 'viktor123';
grant all privileges on nova_api.* to 'nova'@'%' identified by 'viktor123';
grant all privileges on nova.* to 'nova'@'localhost' identified by 'viktor123';
grant all privileges on nova.* to 'nova'@'%' identified by 'viktor123';
grant all privileges on nova_cell0.* to 'nova'@'localhost' identified by 'viktor123';
grant all privileges on nova_cell0.* to 'nova'@'%' identified by 'viktor123';


#Create nova user
openstack user create --domain default --password-prompt nova
openstack role add --project service --user nova admin

#Create the service
openstack service create --name nova --description "Openstack compute" compute

openstack endpoint create --region RegionOne compute public http://10.0.11.160:8774/v2.1
openstack endpoint create --region RegionOne compute internal http://10.0.11.160:8774/v2.1
openstack endpoint create --region RegionOne compute admin http://10.0.11.160:8774/v2.1

#Create placement user
openstack user create --domain default --password-prompt placement
openstack role add --project service --user placement admin

#service and endpoints

openstack service create --name placement --description "Placement api" placement

openstack endpoint create --region RegionOne placement public http://10.0.11.160:8778
openstack endpoint create --region RegionOne placement internal http://10.0.11.160:8778
openstack endpoint create --region RegionOne placement admin http://10.0.11.160:8778


apt-get install nova-api nova-conductor nova-consoleauth nova-novncproxy nova-scheduler nova-placement-api -y

vi /etc/nova/nova.conf

[api_database]
connection = mysql+pymysql://nova:viktor123@10.0.11.160/nova_api

[database]
connection = mysql+pymysql://nova:viktor123@10.0.11.160/nova

[default]
transport_url = rabbit://openstack:viktor123@10.0.11.160
my_ip = 10.0.11.160
use_neutron = True
firewall_driver = nova.virt/firewall.NoopFirewallDrive

[api]
auth_strategy = keystone

[keystone_authtoken]
auth_url = http://10.0.11.160:5000
memcached_servers = 10.0.11.160:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = nova
password = nova123

[vnc]
enabled = true
server_listen = $my_ip
server_proxyclient_address = $my_ip

[glance]
api_servers = http://10.0.11.160:9292

[olso_concurrency]
lock_path = /var/lib/nova/tmp

[placement]
auth_url = http://10.0.11.160:5000
os_region_name = RegionOne
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = placement
password = placement123


##Seed DB
su -s /bin/sh -c "nova-manage api_db sync" nova
su -s /bin/sh -c "nova-manage cell_v2 map_cell0" nova

su -s /bin/sh -c "nova-manage cell_v2 create_cell --name=cell1 --verbose" nova
su -s /bin/sh -c "nova-manage db sync" nova

systemctl restart nova-api nova-consoleauth nova-scheduler nova-conductor nova-novncproxy


#Intall nova on compute node
apt-get install nova-compute

vi /etc/nova/nova.conf

[default]
transport_url = rabbit://openstack:viktor123@10.0.11.160
my_ip = Compute_ip
use_neutron = true
firewall_driver = nova.virt.firewall.NoopFirewallDriver


[api]
auth_strategy = keystone

[keystone_authtoken]
auth_url = http://10.0.11.160:5000
memcached_servers = 10.0.11.160:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = nova
password = nova123

[vnc]
enabled = true
server_listen = $my_ip
server_proxyclient_address = $my_ip

[glance]
api_servers = http://10.0.11.160:9292

[olso_concurrency]
lock_path = /var/lib/nova/tmp

[placement]
auth_url = http://10.0.11.160:5000
os_region_name = RegionOne
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = placement
password = placement123

[libvirt]
virt_type = qemu


chown -R nova: /etc/nova
chown -R nova: /var/lib/nova
systemctl restart nova-compute restart

#Check if node support acceleration
egrep -c '(vmx|svm)' /proc/cpuinfo

#Finilizing nova installation on the controller node
su -s /bin/sh -c "nova-manage cell_v2 discover_hosts --verbose" nova
su -s /bin/sh -c "nova-manage db sync" nova

#Check 
openstack compute service list


###Neutron install
#On controller node

#Create database
create database neutron;
grant all privileges on neutron.* to 'neutron'@'localhost' identified by 'viktor123';
grant all privileges on neutron.* to 'neutron'@'%' identified by 'viktor123';

#Setup user
openstack user create --domain default --password-prompt neutron
openstack role add --project service --user neutron admin

openstack service create --name neutron --description "Openstack networking" network
openstack endpoint create --region RegionOne network public http://10.0.11.160:9696
openstack endpoint create --region RegionOne network internal http://10.0.11.160:9696
openstack endpoint create --region RegionOne network admin http://10.0.11.160:9696


apt-get install neutron-server neutron-plugin-ml2 neutron-linuxbridge-agent neutron-dhcp-agent neutron-metadata-agent -y

chown -R neutron: /etc/neutron/
chown -R neutron: /var/lib/neutron/

vi /etc/neutron/neutron.conf

[database]
connection = mysql+pymysql://neutron:viktor123@10.0.11.160/neutron

[default]
core_plugin = ml2
service_plugins =
transport_url = rabbit://openstack:viktor123@10.0.11.160
auth_strategy = keystone
notify_nova_on_port_status_changes = true
notify_nova_on_port_data_changes = true

[keystone_authtoken]
auth_url = http://10.0.11.160:5000
memcached_servers = 10.0.11.160:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = neutron
password = neutron123

[nova]
auth_url = http://10.0.11.160:5000
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = nova
password = nova123


vi /etc/neutron/plugins/ml2/ml2_conf.ini

[ml2]
type_drivers = flat,vlan
tenant_network_types = 
mechanism_drivers = linuxbridge
extension_drivers = port_security

[ml2_type_flat]
flat_networks = provider

[securitygroup]
enable_ipset = true

vi /etc/neutron/plugins/ml2/linuxbridge_agent.ini

[linux_bridge]
physical_interface_mappings = provider:IFACE

[vxlan]
enable_vxlan = false

[securitygroup]
enable_security_group = true
firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver

vi /etc/neutron/dhcp_agent.ini

[default]
interface_driver = linuxbridge
dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq
enable_isolated_metadata = true

vi /etc/neutron/metadata_agent.ini
#secret generation: openssl rand -hex 10
[default]
nova_metadata_host = 10.0.11.160
metadata_proxy_shared_secret = 56373cd8a589377798d4


vi /etc/nova/nova.conf

[neutron]

url = http://10.0.11.160:9696
auth_url = http://10.0.11.160:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionOne
project_name = service
username = neutron
password = neutron123
service_metadata_proxy = true
metadata_proxy_shared_secret = SECRET

#Seed neutron db
su -s /bin/sh -c "neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head" neutron

systemctl restart nova-api neutron-server neutron-linuxbridge-agent neutron-dhcp-agent neutron-metadata-agent


##Install neutron on the compute nodes
apt-get install neutron-linuxbridge-agent -y

chown -R neutron: /etc/neutron/
chown -R neutron: /var/lib/neutron/

vi /etc/neutron/neutron.conf

[default]
transport_url = rabbit://openstack:viktor123@10.0.11.160
auth_strategy = keystone

[keystone_authtoken]
auth_url = http://10.0.11.160:5000
memcached_servers = 10.0.11.160:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = neutron
password = neutron123


vi /etc/neutron/plugins/ml2/linuxbridge_agent.ini

[linux_bridge]
physical_interface_mappings = provider:IFACE

[vxlan]
enable_vxlan = false

[securitygroup]
enable_security_group = true
firewall_driver = neutron.agent.linux.iptables_firewall.IptablesFirewallDriver

vi /etc/nova/nova.conf

[neutron]
url = http://10.0.11.160:9696
auth_url = http://10.0.11.160:5000
auth_type = password
project_domain_name = default
user_domain_name = default
region_name = RegionOne
project_name = service
username = neutron
password = neutron123

systemctl restart nova-compute neutron-linuxbridge-agent

#Verify neutron
openstack network agent list


### Dashboard service - horizon install
#on controller node

apt-get install openstack-dashboard -y

vi /etc/openstack-dashboard/local_settings.py

OPENSTACK_HOST = "10.0.11.160"
OPENSTACK_KEYSTONE_URL = "http://%s:5000/v3" % OPENSTACK_HOST
OPENSTACK_KEYSTONE_DEFAULT_ROLE = "user"
OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = "Default"
ALLOWED_HOSTS = ['*',]

SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
CACHES = {
    'default': {
	    'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache',
		'LOCATION': '10.0.11.160:11211',
	}}

OPENSTACK_API_VERSIONS = {
	"identity": 3,
	"image": 2,
	"volume": 2,
}

OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True

OPENSTACK_NEUTRON_NETWORK = {
'enable_router': False,
'enable_quotas': False,
'enable_ipv6': False,
'enable_distributed_router': False,
'enable_ha_router': False,
'enable_lb': False,
'enable_firewall': False,
'enable_vpn': False,
'enable_fip_topology_check': False,
}

TIME_ZONE = "TIME_ZONE"

vi /etc/apache2/conf-available/openstack-dashboard.conf
WSGIApplicationGroup %{GLOBAL}

systemctl restart apache2


##Cinder install for block storage
#on the controller

#Create database
create database cinder;
grant all privileges on cinder.* to 'cinder'@'localhost' identified by 'viktor123';
grant all privileges on cinder.* to 'cinder'@'%' identified by 'viktor123';

#Create user
openstack user create --domain default --password-prompt cinder
openstack role add --project service --user cinder admin

#create services
openstack service create --name cinderv2 --description "Openstack block storage" volumev2
openstack service create --name cinderv3 --description "Openstack block storage" volumev3

#v2 endpoints
openstack endpoint create --region RegionOne volumev2 public http://10.0.11.160:8776/v2/%\(project_id\)s
openstack endpoint create --region RegionOne volumev2 internal http://10.0.11.160:8776/v2/%\(project_id\)s
openstack endpoint create --region RegionOne volumev2 admin http://10.0.11.160:8776/v2/%\(project_id\)s

#v3 endpoints
openstack endpoint create --region RegionOne volumev3 public http://10.0.11.160:8776/v3/%\(project_id\)s
openstack endpoint create --region RegionOne volumev3 internal http://10.0.11.160:8776/v3/%\(project_id\)s
openstack endpoint create --region RegionOne volumev3 admin http://10.0.11.160:8776/v3/%\(project_id\)s


apt-get install cinder-api cinder-scheduler -y

chown -R cinder: /etc/cinder
chown -R cinder: /var/lib/cinder

vi /etc/cinder/cinder.conf

[database]
connection = mysql+pymysql://cinder:viktor123@10.0.11.160/cinder

[default]
transport_url = rabbit://openstack:viktor123@10.0.11.160
my_ip = 10.0.11.160

[api]
auth_strategy = keystone

[keystone_authtoken]
auth_url = http://10.0.11.160:5000
memcached_servers = 10.0.11.160:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = cinder
password = cinder123

[oslo_concurrency]
lock_path = /var/lib/cinder/tmp


#Seed db
su -s /bin/sh -c "cinder-manage db sync" cinder

vi /etc/nova/nova.conf

[cinder]
os_region_name = RegionOne

systemctl restart nova-api cinder-scheduler apache2


##install cinder on the block storage node
apt-get install lvm2 thin-provisioning-tools cinder-volume -y

#Create pv and vg with the spare disk
pvcreate /dev/sdb && vgcreate cinder-volumes /dev/sdb

vi /etc/lvm/lvm.conf
filter = ["a/sdb/", "r/.*/"]

chown -R cinder: /etc/cinder
chown -R cinder: /var/lib/cinder

vi /etc/cinder/cinder.conf

[database]
connection = mysql+pymysql://cinder:viktor123@10.0.11.160/cinder

[default]
transport_url = rabbit://openstack:viktor123@10.0.11.160
auth_strategy = keystone
my_ip = BLOCK_NODE_IP
enable_backends = lvm
glance_api_servers = http://10.0.11.160:9292

[oslo_concurrency]
lock_path = /var/lib/cinder/tmp

[keystone_authtoken]
auth_url = http://10.0.11.160:5000
memcached_servers = 10.0.11.160:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = cinder
password = cinder123

[lvm]
volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver
volume_group = cinder-volumes
iscsi_protocol = iscsi
iscsi_helper = tgtadm

systemctl restart cinder-volume tgt

#Verify
openstack volume service list


##Swift installation for object storage
#on the controller create user and give him a role
openstack user create --domain default --password-prompt swift
openstack role add --project service --user swift admin

#Service create

openstack service create --name swift --description "openstack object storage" object-store
openstack endpoint create --region RegionOne object-store public http://10.0.11.160:8080/v1/AUTH_%\(project_id\)s
openstack endpoint create --region RegionOne object-store internal http://10.0.11.160:8080/v1/AUTH_%\(project_id\)s
openstack endpoint create --region RegionOne object-store admin http://10.0.11.160:8080/v1

apt-get install swift swift-proxy python-swiftclient -y

mkdir /etc/swift
#for ubuntu 18 stable/rocky for ubuntu 16 stable/pike
curl -o /etc/swift/proxy-server.conf https://git.openstack.org/cgit/openstack/swift/plain/etc/proxy-server.conf-sample?h=stable/rocky

vi /etc/swift/proxy-server.conf

[default]
bind_port = 8080
user = swift
swift_dir = /etc/swift

[pipeline:main]
#Remove tempurl and tempauth modules and add the authtoken and keystoneauth modules
pipeline = catch_errors gatekeeper healthcheck proxy-logging cache container_sync bulk ratelimit authtoken keystoneauth copy container-quotas account-quotas slo dlo versioned_writes symlink proxy-logging proxy-server

[app:proxy-server]
use = egg:swift#proxy

account_autocreate = True

[filter:keystoneauth]
use = egg:swift#keystoneauth
operator_roles = admin,user

[filter:authtoken]
paste.filter_factory = keystonemiddleware.auth_token:filter_factory
auth_url = http://10.0.11.160:5000
memcached_servers = 10.0.11.160:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = swift
password = swift123
delay_auth_decision = True

[filter:cache]
use = egg:swift#memcache
memcache_servers = 10.0.11.160:11211

#On the object storage nodes
apt-get install xfsprogs rsync -y

#Format drives
mkfs.xfs /dev/drive1
mkfs.xfs /dev/drive2

mkdir -p /srv/node/drive1
mkdir -p /srv/node/drive2

vi /etc/fstab
/dev/drive1  /srv/node/drive1 xfs  noatime,nodiratime,nobarrier,logbufs=8 0 2
/dev/drive2  /srv/node/drive2 xfs  noatime,nodiratime,nobarrier,logbufs=8 0 2

mount -a

vi /etc/rsyncd.conf

uid = swift
gid = swift
log file = /var/log/rsyncd.log
pid file = /var/run/rsyncd.pid
address = 10.0.11.152

[account]
max connections = 2
path = /srv/node
read only = False
lock file = /var/lock/account.lock

[container]
max connections = 2
path = /srv/node
read only = False
lock file = /var/lock/container.lock

[object]
max connections = 2
path = /srv/node
read only = False
lock file = /var/lock/object.lock

vi /etc/default/rsync
RSYNC_ENABLE = true

systemctl restart rsync


apt-get install swift swift-account swift-container swift-object -y

curl -o /etc/swift/account-server.conf https://git.openstack.org/cgit/openstack/swift/plain/etc/account-server.conf-sample?h=stable/rocky
curl -o /etc/swift/container-server.conf https://git.openstack.org/cgit/openstack/swift/plain/etc/container-server.conf-sample?h=stable/rocky
curl -o /etc/swift/object-server.conf https://git.openstack.org/cgit/openstack/swift/plain/etc/object-server.conf-sample?h=stable/rocky

vi /etc/swift/account-server.conf

[default]
bind_ip = SERVER_IP
bind_port = 6202
user = swift
swift_dir = /etc/swift
devices = /srv/node
mount_check = True

[pipeline:main]
pipeline = healthcheck recon account-server

[filter:recon]
use = egg:swift#recon

recon_cache_path = /var/cache/swift

vi /etc/swift/container-server.conf

[default]
bind_ip = SERVER_IP
bind_port = 6201
user = swift
swift_dir = /etc/swift
devices = /srv/node
mount_check = True

[pipeline:main]
pipeline = healthcheck recon container-server

[filter:recon]
use = egg:swift#recon

recon_cache_path = /var/cache/swift


vi /etc/swift/object-server.conf

[default]
bind_ip = SERVER_IP
bind_port = 6200
user = swift
swift_dir = /etc/swift
devices = /srv/node
mount_check = True

[pipeline:main]
pipeline = healthcheck recon object-server

[filter:recon]
use = egg:swift#recon

recon_cache_path = /var/cache/swift
recon_lock_path = /var/lock

chown -R swift: /srv/node

##Executed on the controller

cd /etc/swift
swift-ring-builder account.builder create 10 3 1

#add each node and drive to ring
swift-ring-builder account.builder add --region 1 --zone 1 --ip OBJECT_NODE_IP --port 6202 --device DEVICE1 --weight 100
swift-ring-builder account.builder add --region 1 --zone 1 --ip OBJECT_NODE_IP --port 6202 --device DEVICE2 --weight 100

#verify the ring
swift-ring-builder account.builder
#rebalance the ring
swift-ring-builder account.builder rebalance

#Create base container.builder file
swift-ring-builder container.builder create 10 3 1

#as many as the devices
swift-ring-builder container.builder add --region 1 --zone 1 --ip OBJECT_NODE_IP --port 6201 --device DEVICE --weight 100

swift-ring-builder container.builder
swift-ring-builder container.builder rebalance


#Create object.builder file
swift-ring-builder object.builder create 10 3 1

#as many as the devices
swift-ring-builder object.builder add --region 1 --zone 1 --ip OBJECT_NODE_IP --port 6200 --device DEVICE --weight 100

swift-ring-builder object.builder
swift-ring-builder object.builder rebalance


#Rsync /etc/swift/*.ring.gz to all object nodes /etc/swift and change owner to swift


#Verify swift

curl -o /etc/swift/swift.conf https://git.openstack.org/cgit/openstack/swift/plain/etc/swift.conf-sample?h=stable/rocky

openssl rand -hex 6

vi /etc/swift/swift.conf
[swift-hash]

swift_hash_path_suffix = HASH_PATH_SUFFIX
swift_hash_path_prefix = HASH_PATH_PREFIX

[storage-policy:0]
name = Policy-0
default = yes

##Distribute swift.conf to all object nodes /etc/swift/swift.conf 

##Restart services on the controller
systemctl restart memcached swift-proxy

#Start service on object nodes
swift-init all start

##Verify

#show status
swift stat
openstack container create container1
echo "TEST" > testfile
#upload
openstack object create container1 testfile
#list
openstack object list container1
#download
openstack object save container1 testfile



##Heat installation for ochestration
#on the controller
#Create database

create database heat;
grant all privileges on heat.* to 'heat'@'localhost' identified by 'viktor123';
grant all privileges on heat.* to 'heat'@'%' identified by 'viktor123';

#Create openstack resources
openstack user create --domain default --password-prompt heat
openstack role add --project service --user heat admin

#Services and endpoints
openstack service create --name heat --description "Orchestration" orchestration
openstack service create --name heat-cfn --description "Orchestration" cloudformation

openstack endpoint create --region RegionOne orchestration public http://10.0.11.160:8004/v1/%\(tenant_id\)s
openstack endpoint create --region RegionOne orchestration internal http://10.0.11.160:8004/v1/%\(tenant_id\)s
openstack endpoint create --region RegionOne orchestration admin http://10.0.11.160:8004/v1/%\(tenant_id\)s

openstack endpoint create --region RegionOne cloudformation public http://10.0.11.160:8000/v1
openstack endpoint create --region RegionOne cloudformation internal http://10.0.11.160:8000/v1
openstack endpoint create --region RegionOne cloudformation admin http://10.0.11.160:8000/v1


#Additional identity information

#Create heat domain
openstack domain create --description "Stack projects and users" heat

openstack user create --domain heat --password-prompt heat_domain_admin
openstack role add --domain heat --user-domain heat --user heat_domain_admin admin

#Create the heat_stack_owner role
openstack role create heat_stack_owner

openstack role add --domain heat --user demo heat_stack_owner

#Create the heat_stack_user role
openstack role create heat_stack_user


apt-get install heat-api heat-api-cfn heat-engine

vi /etc/heat/heat.conf

[database]
connection = mysql+pymysql://heat:viktor123@10.0.11.160/heat

[default]
transport_url = rabbit://openstack:viktor123@10.0.11.160
heat_metadata_server_url = http://10.0.11.160:5000
heat_waitcondition_server_url = http://10.0.11.160:8000/v1/waitcondition
stack_domain_admin = heat_domain_admin
stack_domain_admin_password = heat123
stack_user_domain_name = heat

[keystone_authtoken]
auth_url = http://10.0.11.160:5000
memcached_servers = 10.0.11.160:11211
auth_type = password
project_domain_name = default
user_domain_name = default
project_name = service
username = heat
password = heat123


[trustee]
auth_type = password
auth_url = http://10.0.11.160:5000
username = heat
password = heat123
user_domain_name = default

[clients_keystone]
auth_uri = http://10.0.11.160:5000

[ec2authtoken]
auth_uri = http://10.0.11.160:5000


#Init db
su -s /bin/sh -c "heat-manage db_sync" heat

systemctl restart heat-api heat-api-cfn heat-engine


#Verify
openstack orchestration service list



######## Verify cluster #########

#Create network 
openstack network create --share --provider-physical-network provider --provider-network-type flat NAME

#Create subnet
openstack subnet create --network provider --allocation-pool start=172.16.0.0,end=172.16.0.255 --dns-nameserver 8.8.8.8 --gateway 172.16.0.1 --subnet-range 172.16.0.0/24 NAME

#Create flavor(instance type)
openstack flavor create --id 0 --vcpus 1 --ram 1GB --disk 1 m1.nano

#Create key
openstack keypair create --public-key /path/to/pub-key

#Security group rules

openstack security group rule create --proto icmp default
openstack security rule create --proto tcp --dst-port 22 default

#Create the instance
openstack server create --flavor m1.nano --image IMAGE --nic net-id=NETWORK_ID --security-group default --key-name KEYNAME NAME
